{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Nv1S_CYTPR"
      },
      "source": [
        "# API Integration & Prompt Automation\n",
        "Automating Few-Shot and Chain-of-Thought Workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gofi_I_qYTPS"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnS-c2HdYTPS"
      },
      "outputs": [],
      "source": [
        "!pip install openai anthropic python-dotenv pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omFTtP8dYTPT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import BaseModel, ValidationError\n",
        "import openai\n",
        "from anthropic import Anthropic\n",
        "from google.colab import userdata\n",
        "\n",
        "# Store secrets (do this once)\n",
        "userdata.set('OPENAI_API_KEY', 'your-openai-key-here')\n",
        "userdata.set('ANTHROPIC_API_KEY', 'your-anthropic-key-here')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLQIs-UxYTPT"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx4WCZULYTPT"
      },
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize clients\n",
        "openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "anthropic_client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHIkN8V-YTPT"
      },
      "source": [
        "## 3. Example Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-vbEDtqYTPT"
      },
      "outputs": [],
      "source": [
        "%%writefile examples.json\n",
        "{\n",
        "    \"reviews\": [\n",
        "        {\n",
        "            \"text\": \"The food was excellent but service was slow\",\n",
        "            \"analysis\": {\n",
        "                \"rating\": 4,\n",
        "                \"main_points\": [\"great food\", \"slow service\"]\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"math\": [\n",
        "        {\n",
        "            \"problem\": \"If a restaurant has 30 tables with 4 chairs each, how many customers can they seat?\",\n",
        "            \"solution\": \"1. Calculate total chairs: 30 tables * 4 chairs = 120 chairs\\n2. Each chair seats 1 customer\\n3. Total capacity: 120 customers\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjHUTsPVYTPT"
      },
      "outputs": [],
      "source": [
        "with open(\"examples.json\") as f:\n",
        "    EXAMPLES = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_TihZugYTPT"
      },
      "source": [
        "## 4. Core Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brhU03O0YTPU"
      },
      "outputs": [],
      "source": [
        "class ReviewAnalysis(BaseModel):\n",
        "    rating: int\n",
        "    main_points: list[str]\n",
        "    recommendation: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4auztunYTPU"
      },
      "outputs": [],
      "source": [
        "def classify_task(text: str) -> str:\n",
        "    \"\"\"Classify input as review or math problem\"\"\"\n",
        "    math_keywords = ['calculate', 'solve', 'how many', 'math', 'problem']\n",
        "    if any(kw in text.lower() for kw in math_keywords):\n",
        "        return 'math'\n",
        "    return 'review'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p99GB8i7YTPU"
      },
      "outputs": [],
      "source": [
        "def analyze_with_openai(text: str, task_type: str):\n",
        "    \"\"\"Handle OpenAI API calls with error handling\"\"\"\n",
        "    try:\n",
        "        if task_type == 'review':\n",
        "            examples = \"\\n\".join([f\"Review: {ex['text']}\\nAnalysis: {ex['analysis']}\"\n",
        "                                 for ex in EXAMPLES['reviews']])\n",
        "            prompt = f\"\"\"Analyze this review:\\n{text}\\n\\nExamples:\\n{examples}\\n\\nOutput JSON:\"\"\"\n",
        "\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"model=\"gpt-4o-mini-2024-07-18\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                response_format={ \"type\": \"json_object\" }\n",
        "            )\n",
        "            return json.loads(response.choices[0].message.content)\n",
        "\n",
        "        else:  # Math problem\n",
        "            examples = \"\\n\".join([f\"Problem: {ex['problem']}\\nSolution: {ex['solution']}\"\n",
        "                                 for ex in EXAMPLES['math']])\n",
        "            prompt = f\"\"\"Solve this problem step-by-step:\\n{text}\\n\\nExamples:\\n{examples}\\n\\nSolution:\"\"\"\n",
        "\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"OpenAI Error: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4J-eg6TYTPU"
      },
      "outputs": [],
      "source": [
        "def analyze_with_claude(text: str, task_type: str):\n",
        "    \"\"\"Handle Anthropic API calls\"\"\"\n",
        "    try:\n",
        "        if task_type == 'review':\n",
        "            examples = \"\\n\".join([f\"Review: {ex['text']}\\nAnalysis: {ex['analysis']}\"\n",
        "                                 for ex in EXAMPLES['reviews']])\n",
        "            prompt = f\"\"\"Analyze this review:\\n{text}\\n\\nExamples:\\n{examples}\\n\\nOutput JSON:\"\"\"\n",
        "\n",
        "            response = anthropic_client.messages.create(\n",
        "                model=\"claude-3-haiku-20240307\",\n",
        "                max_tokens=1000,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            return json.loads(response.content[0].text)\n",
        "\n",
        "        else:  # Math problem\n",
        "            examples = \"\\n\".join([f\"Problem: {ex['problem']}\\nSolution: {ex['solution']}\"\n",
        "                                 for ex in EXAMPLES['math']])\n",
        "            prompt = f\"\"\"Solve this problem step-by-step:\\n{text}\\n\\nExamples:\\n{examples}\\n\\nSolution:\"\"\"\n",
        "\n",
        "            response = anthropic_client.messages.create(\n",
        "                model=\"claude-3-haiku-20240307\",\n",
        "                max_tokens=1000,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0\n",
        "            )\n",
        "            return response.content[0].text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Claude Error: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xOklmCFYTPU"
      },
      "source": [
        "## 5. Main Execution Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeddFLyhYTPU"
      },
      "outputs": [],
      "source": [
        "def validate_review(response):\n",
        "    \"\"\"Validate review analysis output\"\"\"\n",
        "    try:\n",
        "        return ReviewAnalysis(**response)\n",
        "    except ValidationError as e:\n",
        "        print(f\"Validation Error: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dgva87BYTPU"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    text = input(\"Enter text to analyze: \")\n",
        "    task_type = classify_task(text)\n",
        "\n",
        "    print(f\"\\nAnalyzing as {task_type} task...\\n\")\n",
        "\n",
        "    # Get results from both models\n",
        "    openai_result = analyze_with_openai(text, task_type)\n",
        "    claude_result = analyze_with_claude(text, task_type)\n",
        "\n",
        "    # Validate and display results\n",
        "    if task_type == 'review':\n",
        "        print(\"OpenAI Result:\")\n",
        "        validated = validate_review(openai_result)\n",
        "        print(validated.dict() if validated else \"Invalid response\")\n",
        "\n",
        "        print(\"\\nClaude Result:\")\n",
        "        validated = validate_review(claude_result)\n",
        "        print(validated.dict() if validated else \"Invalid response\")\n",
        "    else:\n",
        "        print(\"OpenAI Solution:\")\n",
        "        print(openai_result)\n",
        "        print(\"\\nClaude Solution:\")\n",
        "        print(claude_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT4js-_UYTPV"
      },
      "outputs": [],
      "source": [
        "# Run the system\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Ih2HutYTPV"
      },
      "source": [
        "## 6. Homework Extensions\n",
        "\n",
        "1. Add Cohere API support\n",
        "2. Implement caching\n",
        "3. Add FastAPI wrapper\n",
        "4. Handle ambiguous inputs\n",
        "\n",
        "Example cache implementation starter code:\n",
        "\n",
        "```python\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache(maxsize=100)\n",
        "def cached_analysis(text: str, model: str):\n",
        "    # Add cache logic here\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}